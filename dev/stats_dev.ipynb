{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from math import sqrt\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from db_helpers import DbHelper\n",
    "from model.params import model_types\n",
    "from utils import filter_df, idx_list, get_distinct_col_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbh = DbHelper(\"LOCAL\")\n",
    "dbh.generate_select_query(\"eval\", \"reg_lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abroca_file = \"abroca_analysis.sql\"\n",
    "abroca_df = dbh.df_from_file(abroca_file)\n",
    "model_types = get_distinct_col_vals(abroca_df, \"model_type\")\n",
    "abroca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    " 'is_female_abroca',\n",
    " 'has_disability_abroca',\n",
    " 'mean_test_roc_auc',\n",
    " 'female_ratio',\n",
    " 'disabled_ratio',\n",
    " 'model_type']\n",
    "df = abroca_df.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_dict(obj: object):\n",
    "    return {x: getattr(obj, x) for x in dir(obj) if (x[0]!=\"_\" and x[:4]not in [\"get_\", \"set_\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polystr = lambda var, n: f\"I({var} ** {n}.0)\"\n",
    "def mk_ols_str(xcol: str,\n",
    "               ycol: str,\n",
    "               n: int,\n",
    "               ):\n",
    "    formula = f\"{ycol} ~ 1 + {xcol}\"\n",
    "    if n > 1:\n",
    "        order_pols = [x for x in range(n+1) if x > 1]\n",
    "        order_strs = [polystr(xcol, x) for x in order_pols]\n",
    "        order_strs.insert(0, formula)\n",
    "        formula = \" + \".join(order_strs)\n",
    "    return formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_lists = {}\n",
    "records = []\n",
    "polys = [2, 1]\n",
    "abrocas = [x for x in cols if \"abroca\" in x]\n",
    "ratios = [x for x in cols if \"ratio\" in x]\n",
    "lp, la = len(polys), len(abrocas)\n",
    "index = idx_list(lp, la)\n",
    "wh = 8\n",
    "fig, axs = plt.subplots(nrows=lp, ncols=la, figsize=(wh, wh))\n",
    "\n",
    "for i, j in index:\n",
    "    n = polys[i]\n",
    "    y = abrocas[j]\n",
    "    ratio = ratios[j]\n",
    "    x = \"mean_test_roc_auc\" if n == 1 else ratio\n",
    "    formula = mk_ols_str(x, y, n)\n",
    "    #for fitdf in [df]:\n",
    "    for mtype in model_types + [\"all\"]:\n",
    "        if mtype in model_types:\n",
    "            fitdf = filter_df(df, \"model_type\", mtype)\n",
    "        else:\n",
    "            fitdf = df\n",
    "        polyfit = smf.ols(formula=formula, data=fitdf).fit()\n",
    "        xlin = np.linspace(fitdf.loc[:, x].min(), fitdf.loc[:, x].max(), 100)\n",
    "        xdf = pd.DataFrame.from_dict({x: xlin})\n",
    "        ylin = polyfit.predict(xdf)\n",
    "        ax = axs[i][j]\n",
    "        sns.scatterplot(fitdf, x=x, y=y, ax=ax)\n",
    "        ax.plot(xlin, ylin)\n",
    "        record = {\n",
    "            \"poly\": n,\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"model_type\": mtype,\n",
    "        }\n",
    "        attr_dict = get_attr_dict(polyfit)\n",
    "        conf_int = polyfit.conf_int().reset_index()\n",
    "        conf_int[\"i\"] = i\n",
    "        conf_int[\"j\"] = j\n",
    "        try:\n",
    "            concat_lists[\"conf_int\"].append(conf_int)\n",
    "        except:\n",
    "            concat_lists[\"conf_int\"] = [conf_int]\n",
    "        print(conf_int)\n",
    "        for key in [x for x in list(attr_dict.keys()) if x not in [\"HC0_se\",\"HC1_se\",\n",
    "                                                                   \"HC2_se\", \"HC3_se\",\n",
    "                                                                   \"resid\",\"wresid\",\n",
    "                                                                   \"fittedvalues\", \"conf_int\",\n",
    "                                                                   \"conf_int_el\", \"eigenvals\",\n",
    "                                                                   \"el_test\",\"f_test\",\"info_criteria\",\n",
    "                                                                   \"load\",\"save\",\"model\"\n",
    "                                                                   ]]:\n",
    "            val = attr_dict[key]\n",
    "            _type = type(val)\n",
    "            if _type in [str, float, int]:\n",
    "                record[key] = val\n",
    "            elif _type == np.float64:\n",
    "                record[key] = float(val)\n",
    "            elif _type == pd.Series:\n",
    "                _df = pd.DataFrame(val)\n",
    "                _df[\"i\"] = i\n",
    "                _df[\"j\"] = j\n",
    "                try:\n",
    "                    concat_lists[key].append(_df)\n",
    "                except:\n",
    "                    concat_lists[key] = [_df]\n",
    "            elif (str(_type)==\"\" or _type==\"\"):\n",
    "                pass\n",
    "            elif \"test\" in key:\n",
    "                pass\n",
    "            elif \"test\" in key:\n",
    "                pass\n",
    "            elif \"test\" in key:\n",
    "                pass\n",
    "            elif \"test\" in key:\n",
    "                pass\n",
    "            elif \"test\" in key:\n",
    "                pass\n",
    "            elif \"test\" in key:\n",
    "                pass\n",
    "            elif \"use_\" in key:\n",
    "                pass\n",
    "            elif \"cov_\" in key:\n",
    "                pass\n",
    "            elif \"compare\" in key:\n",
    "                pass\n",
    "            elif \"summary\" in key:\n",
    "                pass\n",
    "            elif \"resid\" in key:\n",
    "                pass\n",
    "            elif \"remove\" in key:\n",
    "                pass\n",
    "            elif \"predict\" in key:\n",
    "                pass\n",
    "            elif \"initial\" in key:\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(key, str(_type))\n",
    "        records.append(record)\n",
    "        \"\"\"\n",
    "        if (i==j and mtype==\"all\" and i == 1):\n",
    "            attr_dict = get_attr_dict(polyfit)\n",
    "            #save_keys = [x for x in save_keys if x not in [\"bse\", \"params\", \"pvalues\", \"tvalues\"]]\n",
    "            save_keys = [x for x in save_keys if  type(attr_dict[x]) in [pd.Series]]#[str, int, float, np.float64, pd.Series]]\n",
    "            #save_tkeys = [(x, type(attr_dict[x])) for x in list(attr_dict.keys()) if  type(attr_dict[x]) not in [str, int, float, np.float64, pd.Series]]\n",
    "            #print(save_tkeys)\n",
    "            save_dict = {x: attr_dict[x] for x in save_keys}\n",
    "            for x in list(save_dict.keys()):\n",
    "\n",
    "                print(x, str(save_dict[x].values.tolist()))\n",
    "        #    print(get_attr_dict(polyfit))\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rec_df = pd.DataFrame.from_records(records)\n",
    "rec_df.to_sql(\"reg_records\",\n",
    "              dbh.engine,\n",
    "              schema=\"eval\",\n",
    "              if_exists=\"replace\"\n",
    "              )\n",
    "for listkey in list(concat_lists.keys()):\n",
    "    tab = f\"reg_{listkey}\"\n",
    "    _list = concat_lists[listkey]\n",
    "    new_df = pd.concat(_list)\n",
    "    print(new_df)\n",
    "    new_df.to_sql(tab,\n",
    "                  dbh.engine,\n",
    "                  schema=\"eval\",\n",
    "                  if_exists=\"replace\"\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
