{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An Exploration of Analysis Methods on Predictive Models of Student Success\n",
    "\n",
    "### Alex Beckwith\n",
    "### May 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quick Summary\n",
    "\n",
    "- Built a system to train, test, & evaluate machine learning models\n",
    "- Applied to educational data from an online university\n",
    "- Used system to generate predictions\n",
    "- Analyzed results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Presentation Itinerary\n",
    "- Introduction\n",
    "    - Presentation Itinerary\n",
    "    - Quick Summary\n",
    "- Motivations\n",
    "    - Personal Goals\n",
    "    - Research Goals\n",
    "    - Research Questions\n",
    "- Previous Research\n",
    "    - Learning Analytics/Education Data Mining\n",
    "    - Predicting Student Performance\n",
    "    - Model Evaluation Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Experimental Architecture\n",
    "    - Dataset\n",
    "    - Feature Extraction\n",
    "    - Algorithms & Hyperparameters\n",
    "    - Model Pipeline\n",
    "- Model Evaluation\n",
    "    - Naive Averaging\n",
    "    - Null Hypothesis Significance Testing (NHST)\n",
    "    - Bayesian\n",
    "    - Future Research\n",
    "- Wrap Up\n",
    "    - Questions\n",
    "    - Tools Used\n",
    "    - Top References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Abstract \n",
    "\n",
    "Machine learning models are not always evaluated with statistical rigor. This can lead to inferential flaws when assumptions are made about the underlying and performance data, especially when cross-validation is used. In this paper, a Bayesian method of model evaluation is compared to a non-parametric frequentist method. In addition, a metric for analyzing the fairness of a particular algorithm is tested. \n",
    "\n",
    "The evaluation techniques were applied to a dataset of student and course data made available by the Open University. A system was built to train and test predictive models of student success. The aim was to predict students at risk of failing or withdrawing from a course using the first 30 days of data extracted from the virtual learning environment. In an applied setting, these predictions could be used to direct additional resources to at-risk students. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The project included creating a database to cleanse, transform, and analyze the dataset. Features were engineered to use as predictive inputs using a combination of exploratory analysis and inspiration from research. Four different subsets of input features were applied to nine different classification algorithms. Both randomized and exhaustive hyperparameter tuning procedures were experimented with, which created hundreds of distinct hyperparameter settings.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The Bayesian strategy provided more conclusive results by determining a “region of practical equivalence” as opposed to an inability to reject the null hypothesis. The results were similar to findings from research, which typically had tree-based ensemble methods in the upper-equivalence region. \n",
    "\n",
    "The proposed metric for predictive fairness is called the Absolute Between Receiver Operating Characteristic Area (ABROCA). This metric was first introduced at the 2019 International Learning Analytics & Knowledge Conference. A significant relationship between ABROCA and the gender ratio of a course as well as between ABROCA and the ratio of students in a course identifying as having a disability. No significant relationship was found between ABROCA and overall model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots\n",
    "from seaborn import histplot\n",
    "\n",
    "from model.params import show_params\n",
    "from utils.constants import FIGURES_PATH\n",
    "from utils.db_helpers import DbHelper, Table\n",
    "from utils.get_figures import (\n",
    "    PresentationFigures,\n",
    "    SharedFigures,\n",
    "    get_edm_venn,\n",
    "    get_imd_band_displot,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dbh = DbHelper.default()\n",
    "df = dbh.get_table(\"first30\", \"all_features\")\n",
    "features = Table(\"first30\", \"all_features\", df)\n",
    "logos = FIGURES_PATH / \"logos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = dbh.get_table(\"landing\", \"student_info\")\n",
    "df.loc[:, \"imd_band\"] = df.loc[:, \"imd_band\"].apply(\n",
    "    lambda x: \"10-20%\" if x == \"10-20\" else x\n",
    ")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "get_imd_band_displot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = features.df.loc[:, [\"final_result\", \"n_days_active\", \"student_id\"]]\n",
    "gb = df.groupby([\"n_days_active\", \"final_result\"]).count().reset_index()\n",
    "gb.columns = [\"n_days_active\", \"final_result\", \"count\"]\n",
    "gb[gb.loc[:, \"n_days_active\"].apply(lambda x: x in list(range(27, 31)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = features.df.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"avg_days_before_due_submitted\",\n",
    "        \"var_days_before_due_submitted\",\n",
    "        \"stddev_days_before_due_submitted\",\n",
    "        \"min_days_before_due_submitted\",\n",
    "        \"student_id\",\n",
    "        \"n_days_active\",\n",
    "        \"final_result\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "# for x in [y for y in df.columns if \"days\" in y]:\n",
    "#    print(x)\n",
    "fig, ax = subplots(nrows=1, ncols=1, figsize=(16, 9), dpi=200)\n",
    "\n",
    "histplot(\n",
    "    df,\n",
    "    x=\"min_days_before_due_submitted\",\n",
    "    binrange=(-20, 30),\n",
    "    bins=50,\n",
    "    hue=\"final_result\",\n",
    "    hue_order=[\"Distinction\", \"Pass\", \"Fail\", \"Withdrawn\"],\n",
    "    multiple=\"stack\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = subplots(nrows=1, ncols=1, figsize=(16, 9), dpi=200)\n",
    "histplot(\n",
    "    df,\n",
    "    x=\"n_days_active\",\n",
    "    hue=\"final_result\",\n",
    "    hue_order=[\"Distinction\", \"Pass\", \"Fail\", \"Withdrawn\"],\n",
    "    ax=ax,\n",
    "    multiple=\"stack\",\n",
    "    bins=max(gb.loc[:, \"count\"]),\n",
    "    binwidth=1,\n",
    ")\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 9), dpi=800)\n",
    "sns.histplot(\n",
    "    df,\n",
    "    x=\"n_days_active\",\n",
    "    hue=\"final_result\",\n",
    "    hue_order=[\"Distinction\", \"Pass\", \"Fail\", \"Withdrawn\"],\n",
    "    ax=ax,\n",
    "    multiple=\"stack\",\n",
    "    bins=max(gb.loc[:, \"student_id\"]),\n",
    "    binwidth=1,\n",
    ")\n",
    "# figsave(\"n_days_active\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Personal Goals\n",
    "- Research personally relevant topic (education) \n",
    "- Apply knowledge of SQL/Python/data from job as data analyst \n",
    "- Apply interest/knowledge of predictive models learned independently and in data science program\n",
    "- Increase knowledge of statistical evaluation methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Research Goals\n",
    "- Evaluate machine learning models using best practices/methods/tooling\n",
    "- Determine if Bayesian or Frequentist methods are better for machine learning problems\n",
    "- Test new metric for evaluation of model fairness\n",
    "- Apply above goals to case study with education dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Research Questions\n",
    "1. Which models and featuresets are best at predicting student outcomes?\n",
    "2. How do the results differ when models are compared using naive, frequentist and Bayesian methods? \n",
    "3. Is there an association between model predictive performance and Absolute Between Receiver Operating Characteristic Area (ABROCA)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previous Research"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning Analytics/Education Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "get_edm_venn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Educational Data Mining (EDM) is concerned with developing methods for exploring the unique types of data that come from educational environments\n",
    "        - It can be also defined as the application of data mining (DM) techniques to this specific type of dataset that come from educational environments to address important educational questions.\n",
    "- Learning Analytics (LA) can be defined as the measurement, collection, analysis, and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs (Lang, Siemens, Wise, & Gasevic, 2017). There are three crucial elements involved in this definition data, analysis and action.\n",
    "Educational data mining and learning analytics: An updated survey\n",
    "Cristobal Romero | Sebastian Ventura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting Student Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Within EDM/LA, looked speifically at predicting student performance\n",
    "- Important to:\n",
    "    - detect early to divert resources to students in need\n",
    "    - Trace knowledge transfer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Most common types of prediction:\n",
    "1. Classification\n",
    "2. Regression\n",
    "3. Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Common Predictions:\n",
    "1. Final outcome\n",
    "    - Dropout\n",
    "    - Pass/Fail\n",
    "2. Final grades\n",
    "3. Deadline compliance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Most common algorithms:\n",
    "1. Tree-based\n",
    "    - Decision Tree\n",
    "    - Random Forest\n",
    "    - Boosted\n",
    "2. Regression\n",
    "    - Logistic Regression\n",
    "    - Linear Regression\n",
    "4. Support Vector Machines\n",
    "5. Bayesian\n",
    "    - Naive Bayes\n",
    "6. K-Nearest-Neighbor\n",
    "7. Artificial Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- best performing are typically ensemble methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Most common student data sources:\n",
    "1. Computer-based learning environment\n",
    "    - Massive Open Online Course (MOOCs)\n",
    "    - Intelligent Tutoring Systems (ITS)\n",
    "    - Learning Management System\n",
    "2. In-person"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Online -> \n",
    "    More data available\n",
    "    data more consistent\n",
    "Blended learning needs more study"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Most common feature types:\n",
    "1. Academic data\n",
    "    - Assessments\n",
    "2. Demographic data\n",
    "3. Behavior\n",
    "    - Virtual learning environment (VLE) interactions\n",
    "4. Financial aid data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Extraction Strategy\n",
    "- Automated vs Expert Engineered vs Crowdsourced\n",
    "- Automated can perform better, but often less interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.AUTOML_FEATURE_ENGINEERING.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- AutoML Feature Engineering for Student Modeling Yields High Accuracy, but Limited Interpretability\n",
    "- Nigel Bosch - University of Illinois Urbana-Champaign\n",
    "- TSFRESH performed better than both, but was most difficult to interpret\n",
    "- (Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests)\n",
    "- Another source suggested crowdsourcing features in addition to "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Evaluation Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Naive Averaging\n",
    "- Sorting and picking top average value\n",
    "- Hard to extrapolate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Simply sorting by metric and picking top value\n",
    "- Difficult to discern differences between models\n",
    "- No sense of variability between model types/settings\n",
    "- Tough to weigh other factors like interpretability & fit time in justified way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Frequentist (Null Hypothesis Significance Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Single Dataset ROPE Example\n",
    "PresentationFigures.CRITICAL_DIFFERENCE_NEMENYI.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "diagram shows regions for which the null hypothesis cannot be rejected\n",
    "- Friedman test to show whether groups of results are similar (global test)\n",
    "- Post-hoc Nemenyi Test to indicate if significant difference exists between two models\n",
    "- Tough to compare large set of models in this way\n",
    "- Used non-parametric tests to minimize assumptions of distributions of model data\n",
    "- Better for model output data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Single Dataset ROPE Example\n",
    "SharedFigures.BAYES_ROPE_PDF.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Uses Bayesian signed rank test to estimate probability of means being in a prespecified \"Region of Practical Equivalence\" (ROPE)\n",
    "- This test used a ROPE vaue of 0.01, indicating that a 1% difference in means is a wide enough band to consider the performance of two models equivalent for all practical purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Multiple Dataset ROPE Example:\n",
    "SharedFigures.BAYES_ROPE_POSTERIOR.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- A Bayesian posterior plot resulting from a Bayesian hierarchical correlated t-test\n",
    "- visualizes the results of Markov-Chain Monte Carlo (MCMC) sampling for the comparison of two models X and Y\n",
    "- The estimated probability of each outcome is the proportion of samples that fall in each section of the plot.\n",
    "- \"heavier\" than signed rank test, so less convenient\n",
    "- baycomp uses hierarchical for multiple datasets, signed rank for single"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ABROCA | Slicing Analysis\n",
    "### (Absolute Between Receiver Operating Characteristic Area)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Receiver Operating Characteristic (ROC Curve)\n",
    "- A function of the false positive rate to true positive rate over the range of threshold values for a predictor\n",
    "- Area under ROC curve (ROC AUC) commonly used as metric to optimize performance of machine learning models.\n",
    "    - Perfect predictor -> ROC AUC = $1.0$ (correct prediction at all threshold values)\n",
    "    - Random predictor -> ROC AUC = $0.5$ (equally likely to pick correctly or incorrectly at all threshold values) \n",
    "- <a href=\"https://core.ac.uk/download/pdf/55142552.pdf\">Link to more math</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# ROC Curve Example:\n",
    "SharedFigures.HXBOOST_ROC_DEMO.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "explain roc\n",
    "originally used to measure performance of radar equipment\n",
    "- The Receiver Operating Characteristic (ROC) is a plot of the false positive rate to true positive rate over the range of threshold \n",
    "- Area under ROC curve (ROC AUC) commonly used as metric to optimize performance of machine learning models.\n",
    "    - Perfect predictor -> ROC AUC = $1.0$ (correct prediction at all threshold values)\n",
    "    - Random predictor -> ROC AUC = $0.5$ (equally likely to pick correctly or incorrectly at all threshold values) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ABROCA | Slicing Analysis\n",
    "#### (Absolute Between Receiver Operating Characteristic Area)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Proposed as metric with which to compare predictive model fairness\n",
    "    - First introduced at 2019 International Learning Analytics and Knowledge Conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "SharedFigures.HXGBOOST_ABROCA_IS_FEMALE.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- To calculate:\n",
    "    - Split dataset by feature of interest\n",
    "    - Calculate ROC curves for the model on each part of split dataset\n",
    "    - Sum absolute values of between-curve area\n",
    "- How does this relate to fairness?\n",
    "    - A model that predicts subgroups of split dataset equally would have ABROCA = 0 (Same ROC curves, so no area between)\n",
    "    - Hypothesis - Higher ABROCA associated with lower predictive fairness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Open University\n",
    "- Exclusively online university\n",
    "- Largest university by enrollment in UK\n",
    "- Provision one of the largest public learning analytics datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The files\n",
    "- <a href=\"https://analyse.kmi.open.ac.uk/open_dataset\">Open University Learning Analytics Dataset (OULAD)</a>\n",
    "    - <a href=\"http://arx.deidentifier.org/\">Anonymized using ARX anonymization tool</a>\n",
    "- Massive Open Online Courses (MOOCs)\n",
    "    - 2 years (2013 & 2014)\n",
    "    - 7 courses\n",
    "    - 23 presentations\n",
    "    - 32,593 students\n",
    "    - 10,655,280 aggregated Virtual Learning Environment (VLE) activity records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- For course to be included in OULAD\n",
    "    - The number of students in the selected module-presentation is larger than 500.\n",
    "    - At least two presentations of the module exist.\n",
    "    - VLE data are available for the module-presentation (since not all the modules are studied via VLE).\n",
    "    - The module has a significant number of failing students.\n",
    "- (clicks/student/activity/course/day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.SOURCE_ERD_MODEL.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- 7 Tables\n",
    "    - Course Info\n",
    "    - Student Info\n",
    "    - Assessment Info\n",
    "    - Virtual Learning Environment (VLE) Summaries\n",
    "        - (clicks per day, per resource, per student)\n",
    "    - 3 Bridge Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.OULAD_STUDENT_COURSES.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "can add course level details as notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.OULAD_VS_15.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "compared 2013 & 2014 data with sample from 2015 to see if significant changes in deomgraphics\n",
    "at a significance level of 0.05, none would be rejected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Age (age_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.OULAD_15_AGE.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.AGE_BAND_BY_STUDENT.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "print(\"part of effort to anonymize data - big bins\")\n",
    "features.columns[\"age_band\"].desc(\n",
    "    show_props=True, show_nulls=True, show_series_desc=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Index of Multiple Deprivation (imd_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.IMD_BAND_IRELAND.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In the current English Indices of Deprivation 2019 (IoD2019) seven domains of deprivation are considered and weighted as follows,\n",
    "- Income. (22.5%)\n",
    "- Employment. (22.5%)\n",
    "- Education. (13.5%)\n",
    "- Health. (13.5%)\n",
    "- Crime. (9.3%)\n",
    "- Barriers to Housing and Services. (9.3%)\n",
    "- Living Environment. (9.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.OULAD_15_IMD.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "lower = more deprived\n",
    "maybe update data hists to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.IMD_BAND_BY_STUDENT.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "features.columns[\"imd_band\"].desc(\n",
    "    show_series_desc=True, show_props=True, show_nulls=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Region (region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.REGION_BY_STUDENT.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "features.columns[\"region\"].desc(show_series_desc=True, show_props=True, show_nulls=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Highest Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.HIGHEST_EDUCATION_BY_STUDENT.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "features.columns[\"highest_education\"].desc(\n",
    "    show_series_desc=True, show_props=True, show_nulls=True\n",
    ")\n",
    "features.cols[\"highest_education\"].desc(\n",
    "    show_series_desc=True, show_props=True, show_nulls=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Course Domain\n",
    "- STEM or Social Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.COURSE_DOMAIN_BY_STUDENT.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "features.columns[\"is_stem\"].desc(\n",
    "    show_series_desc=True, show_props=True, show_nulls=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.FINAL_RESULT_BY_STUDENT.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "features.columns[\"final_result\"].desc(\n",
    "    show_series_desc=True, show_props=True, show_nulls=True\n",
    ")\n",
    "features.cols[\"final_result\"].desc(\n",
    "    show_series_desc=True, show_props=True, show_nulls=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experimental Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Processing/Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Initial Database Schemas\n",
    "- PostgresQL\n",
    "- Landing\n",
    "    - Raw CSV load\n",
    "- Staging\n",
    "    - Datatype and naming standardization\n",
    "- Main\n",
    "    - Data architecture optimization\n",
    "    - Categorical/text columns stored in tables linked with integer foreign keys\n",
    "    - Joined data saved in views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = dbh.info_schema.loc[:, [\"schema\", \"name\"]]\n",
    "gb = df.groupby([\"schema\"]).count()\n",
    "gb.columns = [\"count\"]\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dbh.show_table(\"landing\", \"student_info\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Landing\n",
    "    - Raw CSV load\n",
    "    - so much text\n",
    "    - 3 columns for unique row\n",
    "- Staging\n",
    "    - Datatype and naming standardization\n",
    "- Main [Maybe ERD]\n",
    "    - Data architecture optimization\n",
    "    - Categorical/text columns stored in tables linked with integer foreign keys\n",
    "    - Joined data saved in views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dbh.show_table(\"main\", \"student_info\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Landing\n",
    "    - Raw CSV load\n",
    "- Staging\n",
    "    - Datatype and naming standardization\n",
    "- Main [Maybe ERD]\n",
    "    - Data architecture optimization\n",
    "    - Categorical/text columns stored in tables linked with integer foreign keys\n",
    "    - Joined data saved in views \n",
    "    - Third Normal Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "# df = dbh.get_table(\"agg\", \"course_activities_by_popularity\")\n",
    "# df = df[df.loc[:, \"activity_type\"].apply(lambda x: x not in  [\"homepage\", \"forumng\"])]\n",
    "# plot = sns.scatterplot(df,\n",
    "#                 #x=\"top_course_activity_by_visits\",\n",
    "#                 #y=\"top_course_activity_by_clicks\",\n",
    "#                 x=\"n_visits\",\n",
    "#                 y=\"n_clicks\",\n",
    "#                 ax=ax,\n",
    "#                 hue=\"activity_type\",\n",
    "#                 alpha=0.75,\n",
    "#                 marker=\"1\"\n",
    "#                 )\n",
    "# sns.Plot.scale()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Extraction\n",
    "- Categories\n",
    "    - Demographic Info\n",
    "    - Course Info\n",
    "    - VLE Interaction Data\n",
    "    - Assignment Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Demographic Info\n",
    "- Course Info\n",
    "    - course level\n",
    "    - course subject\n",
    "- VLE Interaction Data\n",
    "- Assignment Data\n",
    "    - n assignments created/assigned\n",
    "    - calculated moments about the mean for the number of days early or late students turned in assignments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Agg\n",
    "    - Aggregations and calculations\n",
    "- Feat\n",
    "    - First pass at organizing features/calculations for predictive models\n",
    "- First30\n",
    "    - Version of Feat created using first 30 days of class data\n",
    "    - Excluded if withdrew before class day 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Agg\n",
    "    - Aggregations and calculations\n",
    "    - [Avg Assignment Days Early by N Days Active]\n",
    "- Feat\n",
    "    - First pass at organizing features/calculations for predictive models\n",
    "    - [N Days Active]\n",
    "    - [N Distinct Top 5th by Visits]\n",
    "- First30\n",
    "    - Version of Feat created using first 30 days of class data\n",
    "    - Captures 49.60% of all withdrawn students\n",
    "    - Captures 72.22% of students who withdrew after class started\n",
    "    - Soon enough to make actionable difference to most withdrawing/failing students\n",
    "    - [Final Result]\n",
    "- Model\n",
    "    - Logging of model execution data\n",
    "- Eval\n",
    "    - Organization of model analysis calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# sql = f\"select n_days_active, final_result from first30.all_features\"\n",
    "# df = dbh.run_pd_query(sql)\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,9), dpi=1200)\n",
    "# sns.histplot(df,\n",
    "# sql = f\"select {col}, final_result from first30.all_features\"\n",
    "# df = dbh.run_pd_query(sql)\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,9), dpi=1200)\n",
    "# sns.histplot(df,\n",
    "#             x=col,\n",
    "#             hue=\"final_result\",\n",
    "#             multiple=\"stack\",\n",
    "#             hue_order=[\"Distinction\", \"Pass\", \"Fail\", \"Withdrawn\"],\n",
    "#             ax=ax)\n",
    "# plt.title(\"Days Active by Student Count\")\n",
    "# plt.xlim(0, 50)\n",
    "# figsave(col, bbox_inches=\"tight\")\n",
    "# plt.title(\"Days Active by Student Count\")\n",
    "# plt.xlim(0, 50)\n",
    "# figsave(col, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "SharedFigures.N_DAYS_ACTIVE_BY_FINAL_RESULT.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "example of aggregated feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Tables by Schema\n",
    "PresentationFigures.TABLES_BY_SCHEMA.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Agg\n",
    "    - Aggregations and calculations\n",
    "- Feat\n",
    "    - First pass at organizing features/calculations for predictive models\n",
    "- First30\n",
    "    - Version of Feat created using first 30 days of class data\n",
    "- Model\n",
    "    - Logging of model execution data\n",
    "- Eval\n",
    "    - Organization of model analysis calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# sql = f\"select n_total_clicks_by_top_5th_clicks, final_result from first30.all_features\"\n",
    "# df = dbh.run_pd_query(sql)\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,9), dpi=1200)\n",
    "# sns.histplot(df,\n",
    "# sql = f\"select {col}, final_result from first30.all_features\"\n",
    "# df = dbh.run_pd_query(sql)\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,9), dpi=1200)\n",
    "# sns.histplot(df,\n",
    "#             x=col,\n",
    "#             hue=\"final_result\",\n",
    "#             multiple=\"stack\",\n",
    "#             hue_order=[\"Distinction\", \"Pass\", \"Fail\", \"Withdrawn\"],\n",
    "#             ax=ax)\n",
    "# plt.title(\"Total Clicks on Top 5th Popular Sites by Student Count\")\n",
    "# plt.xlim(0, 1000)\n",
    "# figsave(col, bbox_inches=\"tight\")\n",
    "# plt.title(\"Total Clicks on Top 5th Popular Sites by Student Count\")\n",
    "# plt.xlim(0, 1000)\n",
    "# figsave(col, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "SharedFigures.N_TOTAL_CLICKS_BY_TOP_5TH_CLICKS.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "example of expert-rec engineered feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification Algorithms & Hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Grid Search\n",
    "    - Created large arrays of available hyperparameters\n",
    "    - Brute-force search through combination of available hyperparameters\n",
    "- Random Search \n",
    "    - Used GridSearch to limit the bounds of hyperparameter settings\n",
    "    - Created random variables to represent distribution of particular hyperparamters, limited by results from GridSearch\n",
    "    - Ran models where each iteration would pick from a model's available parameter combinations and distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "first will show gridsearch then all examples will be generated randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"hxg_boost\", is_rand=False, n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "note incremental changes\n",
    "random state is a way to freeze a random generator seed\n",
    "only recommended during dev because of \"seed optimization\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">Decision Tree</a> (dtree/DT)\n",
    "- Simple decision rules are optimized from features to sort data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "point out model type code and code for in visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"dtree\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">Ada Boost</a> (ada_boost/ADA)\n",
    "- Ensemble Method\n",
    "- Fits on original dataset, then creates copies which weight incorrectly classified instances more heavily in sequential cycles\n",
    "- Used Decision Tree as base estimator, but can use many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"ada_boost\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html\">Histogram Gradient-Boosting</a> (hxg_boost/HGB)\n",
    "- Similar to Ada Boost, but correction based on gradient of loss function from residuals (gradient descent)\n",
    "- Dataset large enough that Histogram Gradient-Boosting Classifier much faster than Regular Gradient-Boosting Classifier\n",
    "- Histograms increase training efficiency by bucketing continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"hxg_boost\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">Random Forest</a> (rforest/RF)\n",
    "- Ensemble Method\n",
    "- Fits many decision trees on sub-samples of dataset, then uses averaging to boost accuracy and control over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"rforest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">Extra Trees</a> (etree/ET)\n",
    "- Ensemble Method\n",
    "- Fits many decision trees on sub-samples of dataset, then uses averaging to boost accuracy and control over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"etree\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://www.kaggle.com/code/hkapoor/random-forest-vs-extra-trees/notebook\">Extra Trees vs Random Forest</a>\n",
    "- Both construct many decision trees during execution & avg for classification/regression\n",
    "- RF uses bootstrapping to sample subsets, ET by default does not\n",
    "- RF looks for best split, ET randomly selects split\n",
    "- ET typically will have faster fit times & lower variance, higher bias\n",
    "- Performance of ET vs RF is often conditional upon feature selection/noisiness\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">K-Nearest Neighbor</a> (knn/KNN)\n",
    "- Calculates most likely value based on proximity to other points in numeric space    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"knn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">Logistic Regression</a> (logreg/LOG)\n",
    "- Calculates most likely value based on contribution of independednt variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"logreg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">Multi-Layer Perceptron</a> (mlp/MLP)\n",
    "\n",
    "- Simple (vanilla) neural network\n",
    "- Consists of layers of connected nodes with activation functions\n",
    "- Optimizes weights of nodes in each layer using backpropogation during training\n",
    "- Last layer is output layer, which produces most likely result given trained inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"mlp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\">Support Vector Machines (svc/SVC)</a>\n",
    "- A hyperplane is optimized to best split the data into different spatial regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"svc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Not Implemented\n",
    "- Others considered but not implemented due to data preprocessing changes necessary/compute/memory overhead\n",
    "- <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html\">Gaussian</a> \n",
    "    - (Blew up RAM) \n",
    "- <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html\">Naive Bayes</a> \n",
    "    - (Would need to preprocess data differently) \n",
    "- <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">Gradient Boosting</a> \n",
    "    - (Histogram-Based Algorithm more efficient at this scale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "show_params(\"compnb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Preprocessing\n",
    "- Categorical Data -> One Hot\n",
    "- Boolean Data -> Bit $\\left( True = 1, False = 0 \\right)$\n",
    "- Numeric Data -> Standardized $\\left( \\mu = 0, \\sigma = 1 \\right)$\n",
    "- Imputing Strategy = Constant = $0$\n",
    "- Variance Threshold = $0$\n",
    "- Dim Reduction = Principal Component Analysis w/ Maximum Likelihood Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "replaced all missing values with zeros to avoid removing important data - not always the best strategy\n",
    "Standardized -> 0 mean, 1 var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Training Settings\n",
    "- Cross Validation Type = Repeated Stratified K Fold\n",
    "- Cross Validation Splits $ = 5$\n",
    "- Cross Validation Repeats $ = 2$\n",
    "- Runs per Model $ = 10$\n",
    "- Refit Parameter = ROC AUC\n",
    "- Feature to Predict = \"is_withdraw_or_fail\"\n",
    "- Train-Test Split Ratio = $[0.25, 0.35]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = dbh.get_table(\"analysis\", \"all_runs_results\", nrows=10)\n",
    "cols = [\n",
    "    x\n",
    "    for x in df.columns\n",
    "    if (\n",
    "        \"split\" not in x\n",
    "        and x[:4] != \"inc_\"\n",
    "        and x != \"name\"\n",
    "        and \"_id\" not in x\n",
    "        and \"rank\" not in x\n",
    "        and \"timestamp\" not in x\n",
    "    )\n",
    "]\n",
    "cols = [\n",
    "    x\n",
    "    for x in df.columns\n",
    "    if (\n",
    "        \"split\" not in x\n",
    "        and x[:4] != \"inc_\"\n",
    "        and x != \"name\"\n",
    "        and \"_id\" not in x\n",
    "        and \"rank\" not in x\n",
    "        and \"timestamp\" not in x\n",
    "    )\n",
    "]\n",
    "top_10 = df.loc[:, cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Naive Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# ROC AUC by Fit Time - by Model Type\n",
    "SharedFigures.ROC_BY_FIT_TIME.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "drive home the point that just sorting by average is very limiting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Frequentist Model Comparisons\n",
    "SharedFigures.FREQUENTIST_ROPE_WINDOWPANE.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Significance Value = 0.05\n",
    "- recall used non parametric friedman test to check for global difference then used pairwise nemenyi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian Model Comparisons\n",
    "SharedFigures.BAYESIAN_ROPE_WINDOWPANE.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- remem used bayesian signed rank test top check for rope (in this case, rope = 0.002)\n",
    "- models using all features made better predictions than those with one category or more\n",
    "- (this study got those results, another found just assignment data better)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ABROCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "SharedFigures.ABROCA_LOGREG_ETREE.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- compares the ABROCA performance of two models\n",
    "- two models = logreg and etree\n",
    "- for this run, etree has on avg better predictive performance\n",
    "    - follows previous research - more data, better predictions\n",
    "- on abroca, similar for disability, logreg better on gender balance\n",
    "- future - baycomp on abroca as metric to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "SharedFigures.ABROCA_BY_DEMOG_BALANCE.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- follows research -> weak/no relationship between ABROCA and performance (measured by ROC AUC)\n",
    "- follows research -> quadratic relationship between ABROCA & demographic balance\n",
    "- (not necessary to sacrifice predictive performance while researching model fairness)\n",
    "- makes sense because metric modulated is 2D area\n",
    "- & models can be expected to perform worse with less training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Future Research\n",
    "- More comprehensive metric evaulation of ABROCA\n",
    "    - Statistics\n",
    "    - Other demographic characteristics\n",
    "- Refinement of feature extraction\n",
    "- Automated optimization/analysis of hyperparameter probability distributions\n",
    "- Explore relationship between mathematical properties of ROC & ABROCA\n",
    "- Expend more computing resources on hierarchical comparisons rather than different parameterizations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tools Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.PYTHON_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.JUPYTER_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.POSTGRESQL_LOGO.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.PSYCOPG2_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.PANDAS_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.MATPLOTLIB_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.SEABORN_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.NUMPY_LOGO.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bayesian Statistical Tests\n",
    "\n",
    "# <a href=\"https://baycomp.readthedocs.io/en/latest/index.html\">baycomp</a>\n",
    "by:\n",
    "- Janez Demsar\n",
    "- Alessio Benavoli\n",
    "- Giorgio Corani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.SCIPY_LOGO.value.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "PresentationFigures.SCIKIT_LEARN_LOGO.value.image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Top References\n",
    "- <a href=\"https://arxiv.org/pdf/1606.04316\">Time for a Change: a Tutorial for Comparing Multiple Classifiers Through Bayesian Analysis</a>\n",
    "- <a href=\"http://doi.org/10.1145/3303772.3303791\">Evaluating the Fairness of Predictive Student Models Through Slicing Analysis</a>\n",
    "- <a href=\"http://dx.doi.org/10.18608/jla.2018.52.7\">Evaluating Predictive Models of Student Success: Closing the Methodological Gap</a>\n",
    "- <a href=\"http://dx.doi.org/10.18608/jla.2015.22.13\">Exploring the Link between Online Behaviours and Course Performance in Asynchronous Online High School Courses</a>\n",
    "- <a href=\"https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1355\">Educational data mining and learning analytics: An updated survey</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
